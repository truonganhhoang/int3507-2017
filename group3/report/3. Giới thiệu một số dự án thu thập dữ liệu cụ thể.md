## 3. Giới thiệu một số dự án thu thập dữ liệu cụ thể <a name="project-example"></a>
Để dễ dàng thực hành và tiếp cận với các hệ thống thu thập dữ liệu mã nguồn mở. Nhóm có xây dựng các dự án ví dụ. Mã nguồn của dự án ví dụ này trong thư mục `source`.
Để thu thập dữ liệu nhóm chia thành 2 cách tiếp cận. Cách tiếp cận thứ nhất là sử dụng thư viện scrapy. Ngoài ra cách tiếp cận thứ hai là sử dụng các API đã có sẵn tại các trang web.
### 3.1. Ví dụ về thu thập đề thi tại trang tungtung.vn
 Trang web tungtung.vn là website trắc nghiệm kiến thức từ lớp 1 đến lớp 12. Website sử dụng công nghệ react để làm phần giao diện. Với công nghệ này, sẽ khó khăn để thu thập dữ liệu bằng cách sử dụng scrapy. Nhóm đã khai thác và sử dụng API có sẵn từ phía server của tungtung.vn.
 Mã nguồn của ví dụ này tại thư mục `source/fetchApi/tungtung`
 
#### Kết quả đạt được:
 Đề thi: 302 đề thi
 Câu hỏi: hơn 10000 câu hỏi. Mỗi đề thi có từ 10-50 câu trắc nghiệm (bao gồm đáp án)
 
 Dữ liệu thu thập có trong thư mục `source/fetchApi/tungtung/data`

### 3.2. Ví dụ về thu thập hỏi đáp tại trang BigSchool.vn
Trang web BigSchool.vn là trang web hệ thống kiến thức cho học sinh từ lớp 1 đến lớp 12. BigSchool có nhiều chức năng học, thi, chơi, hỏi, đọc. Trong ví dụ này, nhóm thu thập dữ liệu hỏi đáp của BigSchool.vn (https://ask.bigschool.vn)
Dữ liệu trang trả về được gửi từ server vì vậy sử dụng scrapy là cách hiệu quả để thu thập dữ liệu. Mã nguồn của ví dụ này tại `source/scrapy/bigschool` 

Các trang web thu thập được phân trang từ trang 1 đến trang 2594

```python
def start_requests(self):
    urlRelative = 'https://ask.bigschool.vn/ask.html?type=&txtSearch=&o=0&c=-1&s=-1&t=-1&p='
    count = 0
    for page in range(1, 2594):
        count = count + 1
        url = urlRelative + str(page)
        print('page - ', count)
        yield scrapy.Request(url, self.parse) # Thêm các trang để crawler
```

Trích xuất dữ liệu
```python
def parse(self, response):
    for block in response.xpath('//div[@id="result-ask"]/ul/li'):
        # block = response.xpath('//div[@id="result-ask"]/ul/li')[0]
        url = block.xpath('div[contains(@class,"ask-title")]/span/a/@href').extract_first()
        question = "".join(block.xpath('div/a/h5/text()').extract()).strip()
        subject = block.xpath('div[contains(@class,"ask-title")]/span/text()')[0].extract()
        grade = block.xpath('div[contains(@class,"ask-title")]/span/text()')[1].extract()

        record = {'question': question, 'subject': subject, 'grade': grade, 'url': url}
        print(record)

        yield record
```

Lưu dữ liệu
```python
def save(self, item):
    client = MongoClient('localhost', 27017)
    db = client.data_crawler
    bigschool = db.bigschool
    bigschool.update(item, True)
    return item
```

#### Kết quả đạt được
Tiến hành thực hiện crawler trang bigschool, trong 30 phút nhóm đã thu thập được toàn bộ dữ liệu trang hỏi đáp (với 25931 câu hỏi đáp)