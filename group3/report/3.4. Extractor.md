## Kết xuất (Extractor)
### Duyệt tất cả các trang

Cần xác định rõ cấp độ của trang:
-	Start_urls (cấp 1)
-	Trong `parse()` dẫn link đến trang cấp 2 (đây là trang cần duyệt hết các trang con)
-	Parse_next_page: thu thập dữ liệu

```python
def parse_articles_follow_next_page(self, response):
    for article in response.xpath("//article"):
        item = ArticleItem()

        ... trích xuất dữ liệu bài báo ở đây

        yield item

    next_page = response.css("ul.navigation > li.next-page > a::attr('href')")
    if next_page:
        url = response.urljoin(next_page[0].extract())
        yield scrapy.Request(url, self.parse_articles_follow_next_page)
```

Lưu ý: để kiểm tra kết quả trả về khi dùng các selector, sử dụng `crapy shell`

```python
scrapy shell "url"
```

### Thêm thông tin vào hàm `callback`

- Tình huống: khi duyệt các mô phỏng ->… -> trang web công ty -> lấy dữ liệu về công ty
- Vấn đề: muốn lưu thông tin mô phỏng của công ty
- Giải pháp: truyền thêm thông tin vào hàm `callback`.

```python
def parse_page1(self, response):
    item = MyItem()
    item['main_url'] = response.url
    request = scrapy.Request("http://www.example.com/some_page.html",
                             callback=self.parse_page2)
    request.meta['item'] = item
    yield request

def parse_page2(self, response):
    item = response.meta['item']
    item['other_url'] = response.url
    yield item
```

#### Thủ thuật xpath để thu thập dữ liệu một trang web
Tránh sử dụng ``contains(.//text(), ‘search text’) ``, thay vào đó nên dùng ``contains(., ‘search text’) ``

```lightning
Nên dùng: 
>>> xp("//a[contains(., 'Next Page')]")
kết quả: [u'<a href="#">Click here to go to the <strong>Next Page</strong></a>']
```

```lightning
Không nên dùng:
>>> xp("//a[contains(.//text(), 'Next Page')]")
kết quả: []
```

#### Lưu ý sự khác nhau giữa //node[1] và (//node)[1]

- //node[1]: Chọn tất cả các nốt xuất hiện đầu tiên trong các nốt cùng nốt cha tương ứng
- (//node)[1]: Phát hiện tất cả các nốt xuất hiện trong trang web nhưng chỉ lấy một node đầu tiên

#### Khi xác định phần tử bằng class phải cụ thể và cần thiết

Xác định phần tử bởi một lớp Css:

```lightning
>>> sel.css(".content").extract()
[u'<p class="content text-wrap">Some content</p>']
>>> sel.css('.content').xpath('@class').extract()
[u'content text-wrap']
```

#### Mẹo nhỏ để lấy nội dung văn bản

```lightning
//*[not(self::script or self::style)]/text()[normalize-space(.)]
```

Xpath này loại trừ nội dung từ tập lệnh và các thẻ kiểu (style) và đồng thời bỏ qua 
các nút văn bản chỉ có khoảng trắng [1]

[1] http://stackoverflow.com/a/19350897/2572383