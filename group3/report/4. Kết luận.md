## Kết luận

### Ưu điểm

-   Dễ cài đặt, sử dụng, tài liệu rõ ràng, đầy đủ.
-	Cung cấp cơ chế auto-throttling tự động điều chỉnh tốc độ thu thập dữ liệu dựa trên cả máy chủ web và máy tính người dùng.
-	Tự động giữ lại các phiên làm việc. Nó xử lý cookies, đi qua nó một cách dễ dàng thông qua các request. Xác thực cũng 
không phải là trở ngại ngay cả khi mẫu đăng nhập có CSRF token.
-	Nó có thể tránh các bẫy đổi hướng.
-	Lọc các yêu cầu trùng lặp và cho phép tùy chỉnh hành vi lọc bằng việc lưu vào bộ nhớ đệm.
-   Scrapy sử dụng Python giúp việc xử lý dữ liệu chính xác hơn.

### Hạn chế

- Với trường hợp máy khách tải dữ liệu bằng cơ chế không đồng bộ (ajax), scrapy thông thường khó xử lý được. Do đó ta nên sử dụng các web driver thay thế cho scrapy. Có thể dùng Selenium, PhantomJS để xử lý
- Kiến trúc scrapy thiết kế chạy đơn luồng
- Khó xử lý được lượng dữ liệu lớn

Như vậy trong quá trình tìm hiểu các công nghệ crawler, nhóm đã 
phân tích và so sánh ưu nhược điểm giữa các hệ thống. Đối với 
nhu cầu crawl dữ liệu đơn giản, chúng ta nên sử dụng scrapy 
bởi những ưu điểm vượt trội và sự đóng góp tích cực của cộng đồng 
dành cho mã nguồn mở này. Nhìn chung công nghệ có thể thay đổi 
liên tục nhưng cách tiếp cận xây dựng hệ thống crawler vẫn không 
thay đổi. Nếu hiểu sâu về những công nghệ đó, ta có thể xây dựng 
hệ thống tương tự phục vụ cho nghiệp vụ riêng của mình.

Qua việc tìm hiểu này nhóm không chỉ có hiểu biết kĩ hơn về các 
hệ thống crawler, mà còn học tập cách nhìn giải quyết bài toán 
có hệ thống. Thông qua làm bài tập lớn, chúng em có thêm cơ hội 
để nâng cao khả năng làm việc nhóm và có nhiều kiến thức phục vụ 
cho công việc sau này. Nhóm hi vọng báo cáo và các ví dụ về 
chủ đề "Tìm hiểu các mã nguồn mở crawler" này sẽ hữu ích cho 
công việc của các bạn. Nếu cần hỗ trợ về kĩ thuật các bạn có thể 
liên hệ qua email hoặc tạo issue ngay trong chính repo này. 
Chúng mình sẽ hỗ trợ các bạn tối đa.

Chúc các bạn ứng dụng hệ thống crawler hiệu quả cho công việc 
của mình !