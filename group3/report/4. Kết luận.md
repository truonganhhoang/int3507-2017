## Kết luận

### Ưu điểm

-   Dễ cài đặt, sử dụng, tài liệu rõ ràng, đầy đủ.
-	Cung cấp cơ chế auto-throttling tự động điều chỉnh tốc độ thu thập dữ liệu dựa trên cả máy chủ web và máy tính người dùng.
-	Tự động giữ lại các phiên làm việc. Nó xử lý cookies, đi qua nó một cách dễ dàng thông qua các request. Xác thực cũng 
không phải là trở ngại ngay cả khi mẫu đăng nhập có CSRF token.
-	Nó có thể tránh các bẫy đổi hướng.
-	Lọc các yêu cầu trùng lặp và cho phép tùy chỉnh hành vi lọc bằng việc lưu vào bộ nhớ đệm.
-   Scrapy sử dụng Python giúp việc xử lý dữ liệu chính xác hơn.

### Hạn chế

- Với trường hợp máy khách tải dữ liệu bằng cơ chế không đồng bộ (ajax), scrapy thông thường khó xử lý được. Do đó ta nên sử dụng các web driver thay thế cho scrapy. Có thể dùng Selenium, PhantomJS để xử lý
- Kiến trúc scrapy thiết kế chạy đơn luồng
- Khó xử lý được lượng dữ liệu lớn

Như vậy trong quá trình tìm hiểu các công nghệ crawler, nhóm đã phân tích và so sánh ưu nhược điểm giữa các hệ thống. Đối với nhu cầu crawl dữ liệu đơn giản, chúng ta nên sử dụng scrapy bởi những ưu điểm vượt trội và sự đóng góp tích cực của cộng đồng dành cho mã nguồn mở này. Nhìn chung công nghệ có thể thay đổi liên tục nhưng cách tiếp cận xây dựng hệ thống crawler vẫn không thay đổi. Nếu hiểu sâu về những công nghệ đó, ta có thể xây dựng hệ thống tương tự phục vụ cho nghiệp vụ riêng của mình.

Qua việc tìm hiểu này nhóm không chỉ có hiểu biết kĩ hơn về các hệ thống crawler, mà còn học tập cách nhìn giải quyết bài toán có hệ thống. Thông qua làm bài tập lớn, chúng em có thêm cơ hội để nâng cao khả năng làm việc nhóm và có nhiều kiến thức phục vụ cho công việc sau này. Nhóm hi vọng báo cáo và các ví dụ về chủ đề "Tìm hiểu các mã nguồn mở crawler" này sẽ hữu ích cho công việc của các bạn. Nếu cần hỗ trợ về kĩ thuật các bạn có thể liên hệ qua email hoặc tạo issue ngay trong chính repo này. Chúng mình sẽ hỗ trợ các bạn tối đa.

Chúc các bạn ứng dụng hệ thống crawler hiệu quả cho công việc của mình !